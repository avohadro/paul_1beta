import os
import json
import asyncio
from aiogram import Bot, Dispatcher, types
from huggingface_hub import InferenceClient
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# –ö–ª—é—á–∏ –∏–∑ Secrets
TG_TOKEN = os.getenv("TELEGRAM_TOKEN")
HF_TOKEN = os.getenv("HF_TOKEN")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Hugging Face (–≤–º–µ—Å—Ç–æ OpenRouter)
# –í—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –ª—é–±—É—é –º–æ–¥–µ–ª—å, –Ω–∞–ø—Ä–∏–º–µ—Ä: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
client = InferenceClient(token=HF_TOKEN)

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∏–ª—è –∏–∑ JSON (RAG)
print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...")
with open('data.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON
texts = []
# –ï—Å–ª–∏ —ç—Ç–æ —ç–∫—Å–ø–æ—Ä—Ç –∏–∑ Telegram Desktop (—Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–æ–º 'messages')
if isinstance(data, dict) and 'messages' in data:
    raw_messages = data['messages']
# –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
elif isinstance(data, list):
    raw_messages = data
else:
    raw_messages = [data]

for msg in raw_messages:
    if isinstance(msg, dict):
        # –í Telegram —Ç–µ–∫—Å—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π –∏–ª–∏ —Å–ø–∏—Å–∫–æ–º (–µ—Å–ª–∏ –µ—Å—Ç—å —Å—Å—ã–ª–∫–∏/—ç–º–æ–¥–∑–∏)
        t = msg.get('text', '')
        if isinstance(t, list):
            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –∫—É—Å–æ—á–∫–æ–≤
            t = "".join([part if isinstance(part, str) else part.get('text', '') for part in t])
        if t:
            texts.append(str(t))
    elif isinstance(msg, str):
        texts.append(msg)

# –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∑–∞–≥–ª—É—à–∫—É
if not texts:
    texts = ["–ü—Ä–∏–≤–µ—Ç", "–ö–∞–∫ –¥–µ–ª–∞?"]
    print("‚ö†Ô∏è –¢–µ–∫—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ JSON!")
else:
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(texts)} —Å–æ–æ–±—â–µ–Ω–∏–π.")

# –î–∞–ª–µ–µ –∏–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (–æ—Å—Ç–∞–≤–ª—è–π—Ç–µ –∫–∞–∫ –±—ã–ª–æ)
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vector_db = FAISS.from_texts(texts, embeddings)

bot = Bot(token=TG_TOKEN)
dp = Dispatcher()

@dp.message()
async def chat(message: types.Message):
    # –ü–æ–∏—Å–∫ –ø—Ä–∏–º–µ—Ä–æ–≤ —Å—Ç–∏–ª—è
    docs = vector_db.similarity_search(message.text, k=3)
    style_context = "\n---\n".join([d.page_content for d in docs])

    prompt = f"–¢—ã —É—á–∞—Å—Ç–Ω–∏–∫ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞. –¢–≤–æ–∏ –ø—Ä–∏–º–µ—Ä—ã —Å—Ç–∏–ª—è:\n{style_context}\n\n–°–æ–æ–±—â–µ–Ω–∏–µ: {message.text}\n–û—Ç–≤–µ—Ç:"

    try:
        # –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Hugging Face
        response = client.text_generation(
            prompt,
            model="deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B", # –ò–ª–∏ "mistralai/Mistral-7B-Instruct-v0.3"
            max_new_tokens=200,
            temperature=0.7
        )
        await message.answer(response)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")

async def main():
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())